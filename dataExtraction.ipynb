{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import dask.bag as dk\n",
    "import mysql.connector as db\n",
    "from dask import delayed\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection\n",
    "cnx = db.connect(\n",
    "    host=\"localhost\",\n",
    "    port=3306,\n",
    "    user=\"root\",\n",
    "    password=\"root\"\n",
    ")\n",
    "\n",
    "db_curr = cnx.cursor()\n",
    "\n",
    "# Create database if it doesn't exist\n",
    "db_curr.execute(\"CREATE DATABASE IF NOT EXISTS cricket_dataset_practice\")\n",
    "\n",
    "# Connect to the database\n",
    "cnx = db.connect(\n",
    "    host=\"localhost\",\n",
    "    port=3306,\n",
    "    user=\"root\",\n",
    "    password=\"root\",\n",
    "    database=\"cricket_dataset_practice\",\n",
    "    autocommit=True\n",
    ")\n",
    "\n",
    "db_curr = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "db_curr.execute(\"select * from registry;\")\n",
    "rows = db_curr.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('person_id', 'varchar(255)', 'NO', 'PRI', None, ''), ('person_name', 'varchar(255)', 'YES', '', None, '')]\n"
     ]
    }
   ],
   "source": [
    "db_curr.execute(\"\"\"CREATE TABLE registry (\n",
    "    person_id VARCHAR(255) PRIMARY KEY,\n",
    "    person_name VARCHAR(255)\n",
    ");\"\"\")\n",
    "db_curr.execute(\"\"\"DESC registry;\"\"\")\n",
    "print(db_curr.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('match_id', 'int', 'NO', 'PRI', None, ''), ('city', 'varchar(255)', 'YES', '', None, ''), ('gender', 'varchar(255)', 'YES', '', None, ''), ('match_type', 'varchar(255)', 'YES', '', None, ''), ('match_type_number', 'int', 'YES', '', None, ''), ('overs', 'int', 'YES', '', None, ''), ('season', 'varchar(10)', 'YES', '', None, ''), ('team_type', 'varchar(255)', 'YES', '', None, ''), ('venue', 'varchar(255)', 'YES', '', None, ''), ('team1', 'varchar(255)', 'YES', '', None, ''), ('team2', 'varchar(255)', 'YES', '', None, ''), ('toss_winner', 'varchar(255)', 'YES', '', None, ''), ('toss_decision', 'varchar(255)', 'YES', '', None, ''), ('winner', 'varchar(255)', 'YES', '', None, ''), ('outcome_type', 'varchar(255)', 'YES', '', None, ''), ('outcome_value', 'varchar(255)', 'YES', '', None, ''), ('player_of_match', 'varchar(255)', 'YES', 'MUL', None, ''), ('balls_per_over', 'int', 'YES', '', None, '')]\n"
     ]
    }
   ],
   "source": [
    "#create match_details table\n",
    "db_curr.execute(\"\"\"CREATE TABLE match_details (\n",
    "    match_id INT PRIMARY KEY,\n",
    "    city VARCHAR(255),\n",
    "    gender VARCHAR(255),\n",
    "    match_type VARCHAR(255),\n",
    "    match_type_number INT,\n",
    "    overs INT,\n",
    "    season VARCHAR(10),\n",
    "    team_type VARCHAR(255),\n",
    "    venue VARCHAR(255),\n",
    "    team1 VARCHAR(255),\n",
    "    team2 VARCHAR(255),\n",
    "    toss_winner VARCHAR(255),\n",
    "    toss_decision VARCHAR(255),\n",
    "    winner VARCHAR(255),\n",
    "    outcome_type VARCHAR(255),\n",
    "    outcome_value VARCHAR(255),\n",
    "    player_of_match VARCHAR(255),\n",
    "    balls_per_over INT,\n",
    "    FOREIGN KEY (player_of_match) REFERENCES registry(person_id)            \n",
    ");\"\"\")\n",
    "db_curr.execute(\"\"\"DESC match_details;\"\"\")\n",
    "print(db_curr.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('id', 'int', 'NO', 'PRI', None, 'auto_increment'), ('match_id', 'int', 'YES', 'MUL', None, ''), ('person_id', 'varchar(255)', 'YES', 'MUL', None, ''), ('official_type', 'varchar(255)', 'YES', '', None, '')]\n"
     ]
    }
   ],
   "source": [
    "db_curr.execute(\"\"\"CREATE TABLE officials (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    match_id INT,\n",
    "    person_id VARCHAR(255),\n",
    "    official_type VARCHAR(255),\n",
    "    FOREIGN KEY (match_id) REFERENCES match_details(match_id),\n",
    "    FOREIGN KEY (person_id) REFERENCES registry(person_id)\n",
    ");\"\"\")\n",
    "db_curr.execute(\"\"\"DESC officials;\"\"\")\n",
    "print(db_curr.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('id', 'int', 'NO', 'PRI', None, 'auto_increment'), ('match_id', 'int', 'YES', 'MUL', None, ''), ('person_id', 'varchar(255)', 'YES', 'MUL', None, ''), ('team_name', 'varchar(255)', 'YES', '', None, '')]\n"
     ]
    }
   ],
   "source": [
    "db_curr.execute(\"\"\"CREATE TABLE players (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    match_id INT,\n",
    "    person_id VARCHAR(255),\n",
    "    team_name VARCHAR(255),\n",
    "    FOREIGN KEY (match_id) REFERENCES match_details(match_id),\n",
    "    FOREIGN KEY (person_id) REFERENCES registry(person_id)\n",
    ");\"\"\")\n",
    "db_curr.execute(\"\"\"DESC players;\"\"\")\n",
    "print(db_curr.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('id', 'int', 'NO', 'PRI', None, 'auto_increment'), ('match_id', 'int', 'YES', 'MUL', None, ''), ('innings', 'int', 'YES', '', None, ''), ('team', 'varchar(255)', 'YES', '', None, ''), ('overs', 'int', 'YES', '', None, ''), ('balls', 'int', 'YES', '', None, ''), ('batter', 'varchar(255)', 'YES', 'MUL', None, ''), ('bowler', 'varchar(255)', 'YES', 'MUL', None, ''), ('non_striker', 'varchar(255)', 'YES', 'MUL', None, ''), ('runs_batter', 'int', 'YES', '', None, ''), ('runs_extras', 'int', 'YES', '', None, ''), ('runs_total', 'int', 'YES', '', None, ''), ('powerplayed', 'varchar(255)', 'YES', '', None, ''), ('powerplayed_type', 'varchar(255)', 'YES', '', None, ''), ('player_out', 'varchar(255)', 'YES', 'MUL', None, ''), ('dismissal_kind', 'varchar(255)', 'YES', '', None, ''), ('fielders_involved', 'varchar(255)', 'YES', '', None, '')]\n"
     ]
    }
   ],
   "source": [
    "db_curr.execute(\"\"\"CREATE TABLE deliveries (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    match_id INT,  \n",
    "    innings INT,\n",
    "    team VARCHAR(255),\n",
    "    overs INT,\n",
    "    balls INT,\n",
    "    batter VARCHAR(255),\n",
    "    bowler VARCHAR(255),\n",
    "    non_striker VARCHAR(255),\n",
    "    runs_batter INT,\n",
    "    runs_extras INT,\n",
    "    runs_total INT,\n",
    "    powerplayed VARCHAR(255),\n",
    "    powerplayed_type VARCHAR(255),\n",
    "    player_out VARCHAR(255),\n",
    "    dismissal_kind VARCHAR(255),\n",
    "    fielders_involved VARCHAR(255),\n",
    "    FOREIGN KEY (match_id) REFERENCES match_details(match_id),  -- Foreign key to match_details\n",
    "    FOREIGN KEY (batter) REFERENCES registry(person_id),       -- Foreign key to registry for batter\n",
    "    FOREIGN KEY (bowler) REFERENCES registry(person_id),       -- Foreign key to registry for bowler\n",
    "    FOREIGN KEY (non_striker) REFERENCES registry(person_id),  -- Foreign key to registry for non-striker\n",
    "    FOREIGN KEY (player_out) REFERENCES registry(person_id)    -- Foreign key to registry for player_out\n",
    ");\"\"\")\n",
    "db_curr.execute(\"\"\"DESC deliveries;\"\"\")\n",
    "print(db_curr.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_curr.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dataframe_DB(df_match_details,df_officials,df_registry,df_players,df_deliveries):\n",
    "    # Create a new MySQL connection\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        database='cricket_dataset_practice',\n",
    "        user='root',\n",
    "        password='root',\n",
    "        autocommit=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        # Process data and insert into database\n",
    "        df_deliveries.to_sql('deliveries', connection, if_exists='append', index=False)\n",
    "        df_officials.to_sql('officials', connection, if_exists='append', index=False)\n",
    "        df_registry.to_sql('registry', connection, if_exists='append', index=False)\n",
    "        df_players.to_sql('players', connection, if_exists='append', index=False)\n",
    "        df_match_details.to_sql('match_details', connection, if_exists='append', index=False)\n",
    "        \n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_match_data(matchID, data):\n",
    "    d = data['info']\n",
    "    registry = d['registry']['people']\n",
    "    \n",
    "    # Create a dictionary to store the match details\n",
    "    match = {\n",
    "        \"match_id\": matchID, \n",
    "        \"city\": d['city'], \n",
    "        \"gender\": d['gender'],\n",
    "        \"match_type\": d[\"match_type\"], \n",
    "        \"match_type_number\": d[\"match_type_number\"],\n",
    "        \"overs\": d[\"overs\"], \n",
    "        \"season\": d[\"season\"], \n",
    "        \"team_type\": d[\"team_type\"],\n",
    "        \"venue\": d[\"venue\"], \n",
    "        \"team1\": d[\"teams\"][0], \n",
    "        \"team2\": d[\"teams\"][1],\n",
    "        \"toss_winner\": d[\"toss\"][\"winner\"], \n",
    "        \"toss_decision\": d[\"toss\"][\"decision\"],\n",
    "        \"winner\": d[\"outcome\"].get(\"winner\"),\n",
    "        \"outcome_type\": next(iter(d[\"outcome\"].get(\"by\", {})), d[\"outcome\"].get(\"result\")),\n",
    "        \"outcome_value\": d[\"outcome\"].get(\"by\"),\n",
    "        \"player_of_match\": ', '.join(registry.get(p) for p in d.get('player_of_match', [])),\n",
    "        \"balls_per_over\": d[\"balls_per_over\"]\n",
    "    }\n",
    "    \n",
    "    # Create a DataFrame for the match details\n",
    "    df_match_details = pd.DataFrame([match])\n",
    "    \n",
    "    \n",
    "    # Create DataFrames for officials, registry, and players\n",
    "    df_officials = pd.DataFrame([\n",
    "        {\"match_id\": matchID, \"person_id\": registry[person], \"official_type\": off}\n",
    "        for off in d['officials'] for person in d['officials'][off]\n",
    "    ])\n",
    "    \n",
    "    df_registry = pd.DataFrame({\n",
    "        \"person_id\": list(registry.values()),\n",
    "        \"person_name\": list(registry.keys())\n",
    "    }).drop_duplicates()\n",
    "    \n",
    "    df_players = pd.DataFrame([\n",
    "        {\"match_id\": matchID, \"person_id\": registry[player], \"team_name\": team}\n",
    "        for team, players in d['players'].items() for player in players\n",
    "    ])   \n",
    "    \n",
    "    # Create a list to store the deliveries\n",
    "    deliveries = []\n",
    "    \n",
    "    # Iterate over the innings\n",
    "    for inning_count, inning in enumerate(data['innings'], start=1):\n",
    "        team = inning['team']\n",
    "        powerplays = {pp['type']: (int(pp['from']), int(pp['to'])) for pp in inning.get('powerplays', [])}\n",
    "        miscounted = {int(k): v['balls'] for k, v in inning.get('miscounted_overs', {}).items()}\n",
    "        \n",
    "        # Iterate over the overs\n",
    "        for over in inning['overs']:\n",
    "            over_num = over['over']\n",
    "            balls_limit = miscounted.get(over['over'], 6)\n",
    "            \n",
    "            # Iterate over the deliveries\n",
    "            for ball_count, delivery in enumerate(over['deliveries'], start=1):\n",
    "                if ball_count > balls_limit: continue\n",
    "                \n",
    "                # Get the powerplay type\n",
    "                powerplay_type = next((t for t, (s, e) in powerplays.items() if s <= over_num <= e), 'none')\n",
    "                \n",
    "                # Get the wickets\n",
    "                wickets = delivery.get('wickets', [{}])[0]\n",
    "                \n",
    "                # Append the delivery to the list\n",
    "                deliveries.append({\n",
    "                    'innings': inning_count, \n",
    "                    'team': team, \n",
    "                    'overs': over_num, \n",
    "                    'balls': ball_count,\n",
    "                    'batter': registry.get(delivery['batter']), \n",
    "                    'bowler': registry.get(delivery['bowler']),\n",
    "                    'non_striker': registry.get(delivery['non_striker']),\n",
    "                    'runs_batter': delivery['runs']['batter'], \n",
    "                    'runs_extras': delivery['runs']['extras'],\n",
    "                    'runs_total': delivery['runs']['total'],\n",
    "                    'powerplayed': 'yes' if powerplay_type != 'none' else 'no',\n",
    "                    'powerplayed_type': powerplay_type,\n",
    "                    'player_out': registry.get(wickets.get('player_out')),\n",
    "                    'dismissal_kind': wickets.get('kind'),\n",
    "                    'fielders_involved': ', '.join(registry.get(f['name']) for f in wickets.get('fielders', [])) if wickets.get('fielders') else None\n",
    "                })\n",
    "    \n",
    "    # Create a DataFrame for the deliveries\n",
    "    df_deliveries = pd.DataFrame(deliveries)\n",
    "    print(df_deliveries.head(2))\n",
    "    insert_dataframe_DB(df_match_details,df_officials,df_registry,df_players,df_deliveries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            match_ID = os.path.basename(filepath).rsplit('.', 1)[0]  # Extract match_ID\n",
    "            # Process data and return a dictionary or suitable format\n",
    "            extract_match_data(match_ID,data) # Call your function to process the data\n",
    "            return match_ID\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7715\n"
     ]
    }
   ],
   "source": [
    "@delayed\n",
    "def get_json_files(format_path):\n",
    "    files = []\n",
    "    if os.path.isdir(format_path):\n",
    "        for file in os.listdir(format_path):\n",
    "            if file.endswith(\".json\"):\n",
    "                filepath = os.path.join(format_path, file)\n",
    "                files.append(filepath)\n",
    "    return files\n",
    "\n",
    "def process_json_files_parallel(matches_path, formats):\n",
    "    all_filepaths = []\n",
    "\n",
    "    for format_name in formats:\n",
    "        format_path = os.path.join(matches_path, format_name)\n",
    "        files = get_json_files(format_path)\n",
    "        all_filepaths.append(files)\n",
    "\n",
    "    all_filepaths = dk.compute(*all_filepaths)\n",
    "\n",
    "    bags = []\n",
    "    for filepaths in all_filepaths:\n",
    "        bags.append(dk.from_sequence(filepaths))\n",
    "    combined_bag = dk.concat(bags)\n",
    "    results = combined_bag.map(process_json_file).compute()\n",
    "    print(len(results))\n",
    "\n",
    "\n",
    "\n",
    "# Example usage (same as before):\n",
    "matches_path = os.path.join(\"matches\")\n",
    "formats = [\"odis_json\", \"t20s_json\", \"tests_json\"]\n",
    "process_json_files_parallel(matches_path, formats) # assign all the dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match_details, registry, officials, players, deliveries\n",
    "db_curr.execute(\"\"\"TRUNCATE TABLE ;\"\"\")\n",
    "print(db_curr.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from dask import delayed, compute\n",
    "\n",
    "# Define MySQL connection string for SQLAlchemy\n",
    "MYSQL_CONNECTION = \"mysql+mysqlconnector://root:root@localhost/cricket_dataset_practice\"\n",
    "\n",
    "def insert_into_database(df, table_name):\n",
    "    \"\"\" Inserts DataFrame into MySQL using batch insert. \"\"\"\n",
    "    if df.empty:\n",
    "        return  # Skip empty DataFrames\n",
    "\n",
    "    try:\n",
    "        engine = create_engine(MYSQL_CONNECTION)\n",
    "        df.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "        print(f\"Inserted {len(df)} records into {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into {table_name}: {e}\")\n",
    "\n",
    "@delayed\n",
    "def process_json_file(filepath):\n",
    "    \"\"\" Process a single JSON file and insert into MySQL \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            matchID = os.path.basename(filepath).split('.')[0]  # Extract match ID\n",
    "            \n",
    "            d = data.get('info', {})\n",
    "            registry = d.get('registry', {}).get('people', {})\n",
    "\n",
    "            # Match Details Table\n",
    "            match = {\n",
    "                \"match_id\": matchID, \n",
    "                \"city\": d.get('city'), \n",
    "                \"gender\": d.get('gender'),\n",
    "                \"match_type\": d.get(\"match_type\"), \n",
    "                \"match_type_number\": d.get(\"match_type_number\"),\n",
    "                \"overs\": d.get(\"overs\"), \n",
    "                \"season\": d.get(\"season\"), \n",
    "                \"team_type\": d.get(\"team_type\"),\n",
    "                \"venue\": d.get(\"venue\"), \n",
    "                \"team1\": d[\"teams\"][0] if \"teams\" in d else None, \n",
    "                \"team2\": d[\"teams\"][1] if \"teams\" in d else None,\n",
    "                \"toss_winner\": d.get(\"toss\", {}).get(\"winner\"), \n",
    "                \"toss_decision\": d.get(\"toss\", {}).get(\"decision\"),\n",
    "                \"winner\": d.get(\"outcome\", {}).get(\"winner\"),\n",
    "                \"outcome_type\": next(iter(d.get(\"outcome\", {}).get(\"by\", {})), d.get(\"outcome\", {}).get(\"result\")),\n",
    "                \"outcome_value\": json.dumps(d.get(\"outcome\", {}).get(\"by\", {})),  # Store as JSON string\n",
    "                \"player_of_match\": ', '.join(registry.get(p, \"\") for p in d.get('player_of_match', [])),\n",
    "                \"balls_per_over\": d.get(\"balls_per_over\")\n",
    "            }\n",
    "            df_match_details = pd.DataFrame([match])\n",
    "\n",
    "            # Registry Table\n",
    "            df_registry = pd.DataFrame({\n",
    "                \"person_id\": list(registry.values()),\n",
    "                \"person_name\": list(registry.keys())\n",
    "            }).drop_duplicates()\n",
    "\n",
    "            # Officials Table\n",
    "            df_officials = pd.DataFrame([\n",
    "                {\"match_id\": matchID, \"person_id\": registry[person], \"official_type\": off}\n",
    "                for off in d.get('officials', {}) for person in d['officials'][off]\n",
    "            ])\n",
    "\n",
    "            # Players Table\n",
    "            df_players = pd.DataFrame([\n",
    "                {\"match_id\": matchID, \"person_id\": registry[player], \"team_name\": team}\n",
    "                for team, players in d.get('players', {}).items() for player in players\n",
    "            ])\n",
    "\n",
    "            # Deliveries Table\n",
    "            deliveries = []\n",
    "            for inning_count, inning in enumerate(data.get('innings', []), start=1):\n",
    "                for over in inning.get('overs', []):\n",
    "                    for ball_count, delivery in enumerate(over.get('deliveries', []), start=1):\n",
    "                        deliveries.append({\n",
    "                            \"match_id\": matchID,\n",
    "                            \"innings\": inning_count,\n",
    "                            \"team\": inning.get(\"team\"),\n",
    "                            \"overs\": over.get(\"over\"),\n",
    "                            \"balls\": ball_count,\n",
    "                            \"batter\": registry.get(delivery.get(\"batter\")),\n",
    "                            \"bowler\": registry.get(delivery.get(\"bowler\")),\n",
    "                            \"non_striker\": registry.get(delivery.get(\"non_striker\")),\n",
    "                            \"runs_batter\": delivery.get(\"runs\", {}).get(\"batter\"),\n",
    "                            \"runs_extras\": delivery.get(\"runs\", {}).get(\"extras\"),\n",
    "                            \"runs_total\": delivery.get(\"runs\", {}).get(\"total\"),\n",
    "                            \"player_out\": registry.get(delivery.get(\"wickets\", [{}])[0].get(\"player_out\")),\n",
    "                            \"dismissal_kind\": delivery.get(\"wickets\", [{}])[0].get(\"kind\")\n",
    "                        })\n",
    "            df_deliveries = pd.DataFrame(deliveries)\n",
    "\n",
    "            # Insert data into MySQL\n",
    "            insert_into_database(df_registry, \"registry\")\n",
    "            insert_into_database(df_match_details, \"match_details\")            \n",
    "            insert_into_database(df_officials, \"officials\")\n",
    "            insert_into_database(df_players, \"players\")\n",
    "            insert_into_database(df_deliveries, \"deliveries\")\n",
    "\n",
    "            return matchID  # Return match ID for tracking progress\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_json_files_parallel(matches_path, formats):\n",
    "    \"\"\" Process JSON files in parallel using Dask \"\"\"\n",
    "    filepaths = []\n",
    "\n",
    "    for format_name in formats:\n",
    "        format_path = os.path.join(matches_path, format_name)\n",
    "        if os.path.isdir(format_path):\n",
    "            filepaths.extend([os.path.join(format_path, file) for file in os.listdir(format_path) if file.endswith(\".json\")])\n",
    "\n",
    "    # Process files in parallel using Dask\n",
    "    tasks = [process_json_file(fp) for fp in filepaths]\n",
    "    results = compute(*tasks)  # Trigger execution\n",
    "\n",
    "    print(f\"✅ Processed {len([r for r in results if r is not None])} matches successfully!\")\n",
    "\n",
    "# Example Usage:\n",
    "matches_path = \"matches\"\n",
    "formats = [\"odis_json\", \"t20s_json\", \"tests_json\"]\n",
    "process_json_files_parallel(matches_path, formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from dask import delayed, compute\n",
    "\n",
    "# Define MySQL connection string for SQLAlchemy\n",
    "MYSQL_CONNECTION = \"mysql+mysqlconnector://root:root@localhost/cricket_dataset_practice\"\n",
    "\n",
    "def insert_into_database(df, table_name):\n",
    "    \"\"\" Inserts DataFrame into MySQL using batch insert. \"\"\"\n",
    "    if df.empty:\n",
    "        return  # Skip empty DataFrames\n",
    "\n",
    "    try:\n",
    "        engine = create_engine(MYSQL_CONNECTION)\n",
    "        df.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "        print(f\"✅ Inserted {len(df)} records into {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error inserting into {table_name}: {e}\")\n",
    "\n",
    "@delayed\n",
    "def process_json_file(filepath):\n",
    "    \"\"\" Process a single JSON file and insert into MySQL \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            matchID = os.path.basename(filepath).split('.')[0]  # Extract match ID\n",
    "            \n",
    "            d = data.get('info', {})\n",
    "            registry = d.get('registry', {}).get('people', {})\n",
    "\n",
    "            # Registry Table\n",
    "            df_registry = pd.DataFrame({\n",
    "                \"person_id\": list(registry.values()),\n",
    "                \"person_name\": list(registry.keys())\n",
    "            }).drop_duplicates()\n",
    "\n",
    "            insert_into_database(df_registry, \"registry\")\n",
    "\n",
    "\n",
    "            # Match Details Table\n",
    "            match = {\n",
    "                \"match_id\": matchID, \n",
    "                \"city\": d.get('city'), \n",
    "                \"gender\": d.get('gender'),\n",
    "                \"match_type\": d.get(\"match_type\"), \n",
    "                \"match_type_number\": d.get(\"match_type_number\"),\n",
    "                \"overs\": d.get(\"overs\"), \n",
    "                \"season\": d.get(\"season\"), \n",
    "                \"team_type\": d.get(\"team_type\"),\n",
    "                \"venue\": d.get(\"venue\"), \n",
    "                \"team1\": d[\"teams\"][0] if \"teams\" in d else None, \n",
    "                \"team2\": d[\"teams\"][1] if \"teams\" in d else None,\n",
    "                \"toss_winner\": d.get(\"toss\", {}).get(\"winner\"), \n",
    "                \"toss_decision\": d.get(\"toss\", {}).get(\"decision\"),\n",
    "                \"winner\": d.get(\"outcome\", {}).get(\"winner\"),\n",
    "                \"outcome_type\": next(iter(d.get(\"outcome\", {}).get(\"by\", {})), d.get(\"outcome\", {}).get(\"result\")),\n",
    "                \"outcome_value\": json.dumps(d.get(\"outcome\", {}).get(\"by\", {})),  # Store as JSON string\n",
    "                \"player_of_match\": ', '.join(registry.get(p, \"\") for p in d.get('player_of_match', [])),\n",
    "                \"balls_per_over\": d.get(\"balls_per_over\")\n",
    "            }\n",
    "            df_match_details = pd.DataFrame([match])\n",
    "            insert_into_database(df_match_details, \"match_details\") \n",
    "\n",
    "            \n",
    "\n",
    "            # Officials Table\n",
    "            df_officials = pd.DataFrame([\n",
    "                {\"match_id\": matchID, \"person_id\": registry[person], \"official_type\": off}\n",
    "                for off in d.get('officials', {}) for person in d['officials'][off]\n",
    "            ])\n",
    "            insert_into_database(df_officials, \"officials\")\n",
    "\n",
    "            # Players Table\n",
    "            df_players = pd.DataFrame([\n",
    "                {\"match_id\": matchID, \"person_id\": registry[player], \"team_name\": team}\n",
    "                for team, players in d.get('players', {}).items() for player in players\n",
    "            ])\n",
    "            insert_into_database(df_players, \"players\")\n",
    "\n",
    "            # Deliveries Table\n",
    "            deliveries = []\n",
    "            for inning_count, inning in enumerate(data.get('innings', []), start=1):\n",
    "                for over in inning.get('overs', []):\n",
    "                    for ball_count, delivery in enumerate(over.get('deliveries', []), start=1):\n",
    "                        deliveries.append({\n",
    "                            \"match_id\": matchID,\n",
    "                            \"innings\": inning_count,\n",
    "                            \"team\": inning.get(\"team\"),\n",
    "                            \"overs\": over.get(\"over\"),\n",
    "                            \"balls\": ball_count,\n",
    "                            \"batter\": registry.get(delivery.get(\"batter\")),\n",
    "                            \"bowler\": registry.get(delivery.get(\"bowler\")),\n",
    "                            \"non_striker\": registry.get(delivery.get(\"non_striker\")),\n",
    "                            \"runs_batter\": delivery.get(\"runs\", {}).get(\"batter\"),\n",
    "                            \"runs_extras\": delivery.get(\"runs\", {}).get(\"extras\"),\n",
    "                            \"runs_total\": delivery.get(\"runs\", {}).get(\"total\"),\n",
    "                            \"player_out\": registry.get(delivery.get(\"wickets\", [{}])[0].get(\"player_out\")),\n",
    "                            \"dismissal_kind\": delivery.get(\"wickets\", [{}])[0].get(\"kind\")\n",
    "                        })\n",
    "            df_deliveries = pd.DataFrame(deliveries)\n",
    "\n",
    "            # Insert data into MySQL              \n",
    "            insert_into_database(df_deliveries, \"deliveries\")\n",
    "\n",
    "            return matchID  # Return match ID for tracking progress\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "@delayed\n",
    "def process_folder(format_path):\n",
    "    \"\"\" Process a single folder (match format) in parallel \"\"\"\n",
    "    filepaths = [\n",
    "        os.path.join(format_path, file) for file in os.listdir(format_path) if file.endswith(\".json\")\n",
    "    ]\n",
    "\n",
    "    # Process only 5 JSON files in parallel\n",
    "    batch_size = 5  \n",
    "    file_tasks = []\n",
    "    \n",
    "    for i in range(0, len(filepaths), batch_size):\n",
    "        batch = filepaths[i:i + batch_size]\n",
    "        file_tasks.extend([process_json_file(fp) for fp in batch])\n",
    "    \n",
    "    return compute(*file_tasks)  # Execute batch processing for each folder\n",
    "\n",
    "def process_json_files_parallel(matches_path, formats):\n",
    "    \"\"\" Process JSON files across multiple folders in parallel \"\"\"\n",
    "    folder_tasks = []\n",
    "\n",
    "    for format_name in formats:\n",
    "        format_path = os.path.join(matches_path, format_name)\n",
    "        if os.path.isdir(format_path):\n",
    "            folder_tasks.append(process_folder(format_path))  \n",
    "\n",
    "    # Run parallel folder processing\n",
    "    results = compute(*folder_tasks)\n",
    "    \n",
    "    # Flatten results\n",
    "    total_matches = sum(len(res) for res in results if res)\n",
    "    print(f\"✅ Processed {total_matches} matches successfully!\")\n",
    "\n",
    "# Example Usage:\n",
    "matches_path = \"matches\"\n",
    "formats = [\"odis_json\", \"t20s_json\", \"tests_json\"]\n",
    "process_json_files_parallel(matches_path, formats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
